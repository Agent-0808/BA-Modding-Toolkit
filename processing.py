# processing.py

import UnityPy
from UnityPy.enums import ClassIDType as AssetType
from UnityPy.files import ObjectReader as Obj, SerializedFile
import traceback
from pathlib import Path
from PIL import Image
import shutil
import re
import tempfile
from dataclasses import dataclass
from typing import Callable, Any, Literal, NamedTuple

from i18n import t
from utils import CRCUtils, SpineUtils, ImageUtils, no_log

# -------- ç±»åž‹åˆ«å ---------

"""
AssetKey è¡¨ç¤ºèµ„æºçš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œåœ¨ä¸åŒçš„æµç¨‹ä¸­å¯ä»¥ä½¿ç”¨ä¸åŒçš„é”®
    str ç±»åž‹ è¡¨ç¤ºèµ„æºåç§°ï¼Œåœ¨èµ„æºæ‰“åŒ…å·¥å…·ä¸­ä½¿ç”¨
    int ç±»åž‹ è¡¨ç¤º path_id
    NameTypeKey ç±»åž‹ è¡¨ç¤º (åç§°, ç±»åž‹) çš„å‘½åå…ƒç»„
    ContNameTypeKey ç±»åž‹ è¡¨ç¤º (å®¹å™¨å, åç§°, ç±»åž‹) çš„å‘½åå…ƒç»„
"""
class NameTypeKey(NamedTuple):
    name: str | None
    type: str
    def __str__(self) -> str:
        return f"[{self.type}] {self.name}"

class ContNameTypeKey(NamedTuple):
    container: str | None
    name: str
    type: str
    def __str__(self) -> str:
        return f"[{self.type}] {self.name} @ {self.container}"

AssetKey = str | int | NameTypeKey | ContNameTypeKey

# èµ„æºçš„å…·ä½“å†…å®¹ï¼Œå¯ä»¥æ˜¯å­—èŠ‚æ•°æ®ã€PILå›¾åƒæˆ–None
AssetContent = bytes | Image.Image | None  

# ä»Žå¯¹è±¡ç”Ÿæˆèµ„æºé”®çš„å‡½æ•°ï¼ŒæŽ¥æ”¶UnityPyå¯¹è±¡ï¼Œè¿”å›žè¯¥èµ„æºçš„é”®
KeyGeneratorFunc = Callable[[Obj], AssetKey]

# èµ„æºåŒ¹é…ç­–ç•¥é›†åˆï¼Œç”¨äºŽåœ¨ä¸åŒåœºæ™¯ä¸‹ç”Ÿæˆèµ„æºé”®ã€‚
MATCH_STRATEGIES: dict[str, KeyGeneratorFunc] = {
    # path_id: ä½¿ç”¨ Unity å¯¹è±¡çš„ path_id ä½œä¸ºé”®ï¼Œé€‚ç”¨äºŽç›¸åŒç‰ˆæœ¬ç²¾ç¡®åŒ¹é…ï¼Œä¸»è¦æ–¹å¼
    'path_id': lambda obj: obj.path_id,
    # container: ä½¿ç”¨ Unity å¯¹è±¡çš„ container ä½œä¸ºé”®ï¼ˆå¼ƒç”¨ï¼Œå› ä¸ºå‘çŽ°åŒä¸€ä¸ªcontainerä¸‹å¯ä»¥ç”¨é‡åèµ„æºï¼‰
    'container': lambda obj: obj.container,
    # name_type: ä½¿ç”¨ (èµ„æºå, èµ„æºç±»åž‹) ä½œä¸ºé”®ï¼Œé€‚ç”¨äºŽæŒ‰åç§°å’Œç±»åž‹åŒ¹é…ï¼Œåœ¨Asset Packingä¸­ä½¿ç”¨
    'name_type': lambda obj: NameTypeKey(obj.peek_name(), obj.type.name),
    # cont_name_type: ä½¿ç”¨ (å®¹å™¨å, èµ„æºå, èµ„æºç±»åž‹) ä½œä¸ºé”®ï¼Œé€‚ç”¨äºŽæŒ‰å®¹å™¨ã€åç§°å’Œç±»åž‹åŒ¹é…ï¼Œç”¨äºŽè·¨ç‰ˆæœ¬ç§»æ¤
    'cont_name_type': lambda obj: ContNameTypeKey(obj.container, obj.peek_name(), obj.type.name),
}

# æ—¥å¿—å‡½æ•°ç±»åž‹
LogFunc = Callable[[str], None]  

# åŽ‹ç¼©ç±»åž‹
CompressionType = Literal["lzma", "lz4", "original", "none"]  

@dataclass
class SaveOptions:
    """å°è£…äº†ä¿å­˜ã€åŽ‹ç¼©å’ŒCRCä¿®æ­£ç›¸å…³çš„é€‰é¡¹ã€‚"""
    perform_crc: bool = True
    enable_padding: bool = False
    compression: CompressionType = "lzma"

@dataclass
class SpineOptions:
    """å°è£…äº†Spineç‰ˆæœ¬æ›´æ–°ç›¸å…³çš„é€‰é¡¹ã€‚"""
    enabled: bool = False
    converter_path: Path | None = None
    target_version: str | None = None

    def is_enabled(self) -> bool:
        """æ£€æŸ¥Spineå‡çº§åŠŸèƒ½æ˜¯å¦å·²é…ç½®å¹¶å¯ç”¨ã€‚"""
        return (
            self.enabled
            and self.converter_path
            and self.converter_path.exists()
            and self.target_version
            and self.target_version.count(".") == 2
        )

@dataclass
class SpineDowngradeOptions:
    """å°è£…äº†Spineç‰ˆæœ¬é™çº§ç›¸å…³çš„é€‰é¡¹ã€‚"""
    enabled: bool = False
    skel_converter_path: Path | None = None
    atlas_converter_path: Path | None = None
    target_version: str = "3.8.75"

    def is_valid(self) -> bool:
        """æ£€æŸ¥Spineé™çº§åŠŸèƒ½æ˜¯å¦å·²é…ç½®å¹¶å¯ç”¨ã€‚"""
        return (
            self.enabled
            and self.skel_converter_path is not None
            and self.skel_converter_path.exists()
            and self.atlas_converter_path is not None
            and self.atlas_converter_path.exists()
            and self.target_version
            and self.target_version.count(".") == 2
        )

# ====== è¯»å–ä¸Žä¿å­˜ç›¸å…³ ======

def get_unity_platform_info(input: Path | UnityPy.Environment) -> tuple[str, str]:
    """
    èŽ·å– Bundle æ–‡ä»¶çš„å¹³å°ä¿¡æ¯å’Œ Unity ç‰ˆæœ¬ã€‚
    
    Returns:
        tuple[str, str]: (å¹³å°åç§°, Unityç‰ˆæœ¬) çš„å…ƒç»„
                         å¦‚æžœæ‰¾ä¸åˆ°åˆ™è¿”å›ž ("UnknownPlatform", "Unknown")
    """
    if isinstance(input, Path):
        env = UnityPy.load(str(input))
    elif isinstance(input, UnityPy.Environment):
        env = input
    else:
        raise ValueError("input å¿…é¡»æ˜¯ Path æˆ– UnityPy.Environment ç±»åž‹")
    
    for file_obj in env.files.values():
        for inner_obj in file_obj.files.values():
            if isinstance(inner_obj, SerializedFile) and hasattr(inner_obj, 'target_platform'):
                return inner_obj.target_platform.name, inner_obj.unity_version
    
    return "UnknownPlatform", "Unknown"

def load_bundle(
    bundle_path: Path,
    log: LogFunc = no_log
) -> UnityPy.Environment | None:
    """
    å°è¯•åŠ è½½ä¸€ä¸ª Unity bundle æ–‡ä»¶ã€‚
    å¦‚æžœç›´æŽ¥åŠ è½½å¤±è´¥ï¼Œä¼šå°è¯•ç§»é™¤æœ«å°¾çš„å‡ ä¸ªå­—èŠ‚åŽå†æ¬¡åŠ è½½ã€‚
    """

    # 1. å°è¯•ç›´æŽ¥åŠ è½½
    try:
        env = UnityPy.load(str(bundle_path))
        return env
    except Exception as e:
        pass

    # å¦‚æžœç›´æŽ¥åŠ è½½å¤±è´¥ï¼Œè¯»å–æ–‡ä»¶å†…å®¹åˆ°å†…å­˜
    try:
        with open(bundle_path, "rb") as f:
            data = f.read()
    except Exception as e:
        log(f'  âŒ {t("log.file.read_in_memory_failed", name=bundle_path.name, error=e)}')
        return None

    # å®šä¹‰åŠ è½½ç­–ç•¥ï¼šå­—èŠ‚ç§»é™¤æ•°é‡
    bytes_to_remove = [4, 8, 12]

    # 2. ä¾æ¬¡å°è¯•ä¸åŒçš„åŠ è½½ç­–ç•¥
    for bytes_num in bytes_to_remove:
        if len(data) > bytes_num:
            try:
                trimmed_data = data[:-bytes_num]
                env = UnityPy.load(trimmed_data)
                return env
            except Exception as e:
                pass

    log(f'âŒ {t("log.file.load_failed", path=bundle_path)}')
    return None

def save_bundle(
    env: UnityPy.Environment,
    output_path: Path,
    compression: CompressionType = "lzma",
    log: LogFunc = no_log,
) -> bool:
    """
    å°†ä¿®æ”¹åŽçš„ Unity bundle ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ã€‚
    """
    try:
        bundle_data = compress_bundle(env, compression, log)
        with open(output_path, "wb") as f:
            f.write(bundle_data)
        return True
    except Exception as e:
        log(f'âŒ {t("log.file.save_failed", path=output_path, error=e)}')
        log(traceback.format_exc())
        return False

def compress_bundle(
    env: UnityPy.Environment,
    compression: CompressionType = "none",
    log: LogFunc = no_log,
) -> bytes:
    """
    ä»Ž UnityPy.Environment å¯¹è±¡ç”Ÿæˆ bundle æ–‡ä»¶çš„å­—èŠ‚æ•°æ®ã€‚
    compression: ç”¨äºŽæŽ§åˆ¶åŽ‹ç¼©æ–¹å¼ã€‚
                 - "lzma": ä½¿ç”¨ LZMA åŽ‹ç¼©ã€‚
                 - "lz4": ä½¿ç”¨ LZ4 åŽ‹ç¼©ã€‚
                 - "original": ä¿ç•™åŽŸå§‹åŽ‹ç¼©æ–¹å¼ã€‚
                 - "none": ä¸è¿›è¡ŒåŽ‹ç¼©ã€‚
    """
    save_kwargs = {}
    if compression == "original":
        # Not passing the 'packer' argument preserves the original compression.
        pass
    elif compression == "none":
        save_kwargs['packer'] = ""  # An empty string typically means no compression.
    else:
        save_kwargs['packer'] = compression
    
    return env.file.save(**save_kwargs)

def _save_and_crc(
    env: UnityPy.Environment,
    output_path: Path,
    original_bundle_path: Path,
    save_options: SaveOptions,
    log: LogFunc = no_log,
) -> tuple[bool, str]:
    """
    ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºŽç”ŸæˆåŽ‹ç¼©bundleæ•°æ®ï¼Œæ ¹æ®éœ€è¦æ‰§è¡ŒCRCä¿®æ­£ï¼Œå¹¶æœ€ç»ˆä¿å­˜åˆ°æ–‡ä»¶ã€‚
    å°è£…äº†ä¿å­˜ã€CRCä¿®æ­£çš„é€»è¾‘ã€‚

    Returns:
        tuple(bool, str): (æ˜¯å¦æˆåŠŸ, çŠ¶æ€æ¶ˆæ¯) çš„å…ƒç»„ã€‚
    """
    try:
        # å‡†å¤‡ä¿å­˜ä¿¡æ¯å¹¶è®°å½•æ—¥å¿—
        compression_map = {
            "lzma": "LZMA",
            "lz4": "LZ4",
            "none": t("log.compression.none_short"),
            "original": t("log.compression.original_short")
        }
        compression_str = compression_map.get(save_options.compression, save_options.compression.upper())
        crc_status_str = t("common.on") if save_options.perform_crc else t("common.off")
        log(f"  > {t('log.file.saving_bundle_prefix')} [{t('log.file.compression_method', compression=compression_str)}] [{t('log.file.crc_correction', crc_status=crc_status_str)}]")

        # ä»Ž env ç”Ÿæˆä¿®æ”¹åŽçš„åŽ‹ç¼© bundle æ•°æ®
        modified_data = compress_bundle(env, save_options.compression, log)

        final_data = modified_data
        success_message = t("message.save_success")

        if save_options.perform_crc:
            with open(original_bundle_path, "rb") as f:
                original_data = f.read()

            corrected_data = CRCUtils.apply_crc_fix(
                original_data, 
                modified_data, 
                save_options.enable_padding
            )

            if not corrected_data:
                return False, t("message.crc.correction_failed_file_not_generated", name=output_path.name)
            
            final_data = corrected_data
            success_message = t("message.save_and_crc_success")

        # å†™å…¥æ–‡ä»¶
        with open(output_path, "wb") as f:
            f.write(final_data)
        
        return True, success_message

    except Exception as e:
        log(f'âŒ {t("log.file.save_or_crc_failed", path=output_path, error=e)}')
        log(traceback.format_exc())
        return False, t("message.save_or_crc_error", error=e)


# ====== å¯»æ‰¾å¯¹åº”æ–‡ä»¶ ======

def get_filename_prefix(filename: str, log: LogFunc = no_log) -> tuple[str | None, str]:
    """
    ä»Žæ—§ç‰ˆModæ–‡ä»¶åä¸­æå–ç”¨äºŽæœç´¢æ–°ç‰ˆæ–‡ä»¶çš„å‰ç¼€ã€‚
    è¿”å›ž (å‰ç¼€å­—ç¬¦ä¸², çŠ¶æ€æ¶ˆæ¯) çš„å…ƒç»„ã€‚
    """
    # 1. é€šè¿‡æ—¥æœŸæ¨¡å¼ç¡®å®šæ–‡ä»¶åä½ç½®
    date_match = re.search(r'\d{4}-\d{2}-\d{2}', filename)
    if not date_match:
        msg = t("message.search.date_pattern_not_found", filename=filename)
        log(f'  > {t("common.fail")}: {msg}')
        return None, msg

    # 2. å‘å‰æŸ¥æ‰¾å¯èƒ½çš„æ—¥æœé¢å¤–æ–‡ä»¶åéƒ¨åˆ†
    prefix_end_index = date_match.start()
    before_date = filename[:prefix_end_index].removesuffix('-')
    # ä¾‹å¦‚åœ¨ "...-textures-YYYY-MM-DD..." ä¸­çš„ "textures"

    parts = before_date.split('-')
    last_part = parts[-1] if parts else ''
    
    # æ£€æŸ¥æœ€åŽä¸€ä¸ªéƒ¨åˆ†æ˜¯å¦æ˜¯æ—¥æœç‰ˆé¢å¤–çš„èµ„æºç±»åž‹
    resource_types = {
        'textures', 'assets', 'textassets', 'materials',
        "animationclip", "audio", "meshes", "prefabs", "timelines"
    }
    
    if last_part.lower() in resource_types:
        # å¦‚æžœæ‰¾åˆ°äº†èµ„æºç±»åž‹ï¼Œåˆ™å‰ç¼€ä¸åº”è¯¥åŒ…å«è¿™ä¸ªéƒ¨åˆ†
        search_prefix = before_date.removesuffix(f'-{last_part}') + '-'
    else:
        search_prefix = filename[:prefix_end_index]

    return search_prefix, t("message.search.prefix_extracted")

def find_new_bundle_path(
    old_mod_path: Path,
    game_resource_dir: Path | list[Path],
    log: LogFunc = no_log,
) -> tuple[Path | None, str]:
    """
    æ ¹æ®æ—§ç‰ˆModæ–‡ä»¶ï¼Œåœ¨æ¸¸æˆèµ„æºç›®å½•ä¸­æ™ºèƒ½æŸ¥æ‰¾å¯¹åº”çš„æ–°ç‰ˆæ–‡ä»¶ã€‚
    
    Returns:
        tuple[Path | None, str]: (æ‰¾åˆ°çš„è·¯å¾„å¯¹è±¡, çŠ¶æ€æ¶ˆæ¯)
    """
    if not old_mod_path.exists():
        return None, t("message.search.check_file_exists", path=old_mod_path)

    log(t("log.search.searching_for_file", name=old_mod_path.name))

    # 1. æå–æ–‡ä»¶åå‰ç¼€
    if not (prefix_info := get_filename_prefix(str(old_mod_path.name), log))[0]:
        return None, prefix_info[1]
    
    prefix, _ = prefix_info
    log(f"  > {t('log.search.file_prefix', prefix=prefix)}")
    extension = '.bundle'
    extension_backup = '.backup'

    # 2. æ”¶é›†æ‰€æœ‰å€™é€‰æ–‡ä»¶
    search_dirs = [game_resource_dir] if isinstance(game_resource_dir, Path) else game_resource_dir
    
    candidates = [
        file for dir in search_dirs 
        if dir.exists() and dir.is_dir()
        for file in dir.iterdir()
        if file.is_file() and file.name.startswith(prefix) and file.suffix != extension_backup
    ]
    
    if not candidates:
        msg = t("message.search.no_matching_files_in_dir")
        log(f'  > {t("common.fail")}: {msg}')
        return None, msg
    log(f"  > {t('log.search.found_candidates', count=len(candidates))}")

    # 3. åˆ†æžæ—§Modçš„å…³é”®èµ„æºç‰¹å¾
    # å®šä¹‰ç”¨äºŽè¯†åˆ«çš„èµ„æºç±»åž‹
    comparable_types = {AssetType.Texture2D, AssetType.TextAsset, AssetType.Mesh}
    
    if not (old_env := load_bundle(old_mod_path, log)):
        msg = t("message.search.load_old_mod_failed")
        log(f'  > {t("common.fail")}: {msg}')
        return None, msg

    # ä½¿ç”¨æ ‡å‡†ç­–ç•¥ç”Ÿæˆ Keyï¼Œä¿æŒä¸€è‡´æ€§
    key_func = MATCH_STRATEGIES['name_type']
    
    # ä»…æå– Keyï¼Œä¸è¯»å–æ•°æ®
    # ä½¿ç”¨ set æŽ¨å¯¼å¼æž„å»ºæŒ‡çº¹
    old_assets_fingerprint = {
        key_func(obj)
        for obj in old_env.objects
        if obj.type in comparable_types
    }

    if not old_assets_fingerprint:
        msg = t("message.search.no_comparable_assets")
        log(f'  > {t("common.fail")}: {msg}')
        return None, msg

    log(f"  > {t('log.search.old_mod_asset_count', count=len(old_assets_fingerprint))}")

    # 4. éåŽ†å€™é€‰æ–‡ä»¶è¿›è¡ŒæŒ‡çº¹æ¯”å¯¹
    for candidate_path in candidates:
        log(f"  - {t('log.search.checking_candidate', name=candidate_path.name)}")
        
        if not (env := load_bundle(candidate_path, log)):
            continue
        
        # éåŽ†æ–°åŒ…ä¸­çš„å¯¹è±¡ï¼Œä¸€æ—¦å‘çŽ°åŒ¹é…ç«‹å³è¿”å›ž (Early Exit)
        for obj in env.objects:
            if obj.type in comparable_types:
                # åŒæ ·çš„ Key ç”Ÿæˆé€»è¾‘
                candidate_key = key_func(obj)
                if candidate_key in old_assets_fingerprint:
                    msg = t("message.search.new_file_confirmed", name=candidate_path.name)
                    log(f"  âœ… {msg}")
                    return candidate_path, msg
    
    msg = t("message.search.no_matching_asset_found")
    log(f'  > {t("common.fail")}: {msg}')
    return None, msg

# ====== èµ„æºå¤„ç†ç›¸å…³ ======

def _apply_replacements(
    env: UnityPy.Environment,
    replacement_map: dict[AssetKey, AssetContent],
    key_func: KeyGeneratorFunc,
    log: LogFunc = no_log,
) -> tuple[int, list[str], list[AssetKey]]:
    """
    å°†â€œæ›¿æ¢æ¸…å•â€ä¸­çš„èµ„æºåº”ç”¨åˆ°ç›®æ ‡çŽ¯å¢ƒä¸­ã€‚

    Args:
        env: ç›®æ ‡ UnityPy çŽ¯å¢ƒã€‚
        replacement_map: èµ„æºæ›¿æ¢æ¸…å•ï¼Œæ ¼å¼ä¸º { asset_key: content }ã€‚
        key_func: ç”¨äºŽä»Žç›®æ ‡çŽ¯å¢ƒä¸­çš„å¯¹è±¡ç”Ÿæˆ asset_key çš„å‡½æ•°ã€‚
        log: æ—¥å¿—è®°å½•å‡½æ•°ã€‚

    Returns:
        ä¸€ä¸ªå…ƒç»„ (æˆåŠŸæ›¿æ¢çš„æ•°é‡, æˆåŠŸæ›¿æ¢çš„èµ„æºæ—¥å¿—åˆ—è¡¨, æœªèƒ½åŒ¹é…çš„èµ„æºé”®é›†åˆ)ã€‚
    """
    replacement_count = 0
    replaced_assets_log = []
    
    # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ç”¨äºŽæ“ä½œï¼Œå› ä¸ºæˆ‘ä»¬ä¼šä»Žä¸­ç§»é™¤å·²å¤„ç†çš„é¡¹
    tasks = replacement_map.copy()

    for obj in env.objects:
        if not tasks:  # å¦‚æžœæ¸…å•ç©ºäº†ï¼Œå°±æå‰é€€å‡º
            break
        
        try:
            data = obj.read()
            asset_key = key_func(obj)
            
            # è·³è¿‡ asset_key ä¸º None çš„å¯¹è±¡ï¼ˆå¦‚ GameObjectã€Transform ç­‰ï¼‰
            if asset_key is None:
                continue
            
            # é¢å¤–æ£€æŸ¥ï¼šç¡®ä¿ç±»åž‹åœ¨ç™½åå•ä¸­
            if obj.type not in REPLACEABLE_ASSET_TYPES:
                continue

            if asset_key in tasks:
                content = tasks.pop(asset_key)
                resource_name = getattr(data, 'm_Name', t("log.unnamed_resource", type=obj.type.name))
                
                if obj.type == AssetType.Texture2D:
                    data.image = content
                    data.save()
                elif obj.type == AssetType.TextAsset:
                    # content æ˜¯ bytesï¼Œéœ€è¦è§£ç æˆ str
                    data.m_Script = content.decode("utf-8", "surrogateescape")
                    data.save()
                else:
                    # å…¶ä»–ç±»åž‹ç›´æŽ¥è®¾ç½®åŽŸå§‹æ•°æ®
                    obj.set_raw_data(content)

                replacement_count += 1
                key_display = str(asset_key)
                log_message = f"[{obj.type.name}] {resource_name} (key: {key_display})"
                replaced_assets_log.append(log_message)

        except Exception as e:
            resource_name_for_error = obj.peek_name() or t("log.unnamed_resource", type=obj.type.name)
            log(f'  âŒ {t("common.error")}: {t("log.replace_resource_failed", name=resource_name_for_error, type=obj.type.name, error=e)}')

    return replacement_count, replaced_assets_log, list(tasks.keys())

def process_asset_packing(
    target_bundle_path: Path,
    asset_folder: Path,
    output_dir: Path,
    save_options: SaveOptions,
    spine_options: SpineOptions | None = None,
    enable_rename_fix: bool | None = False,
    enable_bleed: bool | None = False,
    log: LogFunc = no_log,
) -> tuple[bool, str]:
    """
    ä»ŽæŒ‡å®šæ–‡ä»¶å¤¹ä¸­ï¼Œå°†åŒåçš„èµ„æºæ‰“åŒ…åˆ°æŒ‡å®šçš„ Bundle ä¸­ã€‚
    æ”¯æŒ .png, .skel, .atlas æ–‡ä»¶ã€‚
    - .png æ–‡ä»¶å°†æ›¿æ¢åŒåçš„ Texture2D èµ„æº (æ–‡ä»¶åä¸å«åŽç¼€)ã€‚
    - .skel å’Œ .atlas æ–‡ä»¶å°†æ›¿æ¢åŒåçš„ TextAsset èµ„æº (æ–‡ä»¶åå«åŽç¼€)ã€‚
    å¯é€‰åœ°å‡çº§ Spine åŠ¨ç”»çš„ Skel èµ„æºç‰ˆæœ¬ã€‚
    å¯é€‰åœ°å¯¹ PNG æ–‡ä»¶è¿›è¡Œ Bleed å¤„ç†ã€‚
    æ­¤å‡½æ•°å°†ç”Ÿæˆçš„æ–‡ä»¶ä¿å­˜åœ¨å·¥ä½œç›®å½•ä¸­ï¼Œä»¥ä¾¿åŽç»­è¿›è¡Œ"è¦†ç›–åŽŸæ–‡ä»¶"æ“ä½œã€‚
    å› ä¸ºæ‰“åŒ…èµ„æºçš„æ“ä½œåœ¨åŽŸç†ä¸Šæ˜¯æ›¿æ¢ç›®æ ‡Bundleå†…çš„èµ„æºï¼Œå› æ­¤é‡Œé¢å¯èƒ½æœ‰æ··ç”¨æ‰“åŒ…å’Œæ›¿æ¢çš„å«æ³•ã€‚
    è¿”å›ž (æ˜¯å¦æˆåŠŸ, çŠ¶æ€æ¶ˆæ¯) çš„å…ƒç»„ã€‚
    
    Args:
        target_bundle_path: ç›®æ ‡Bundleæ–‡ä»¶çš„è·¯å¾„
        asset_folder: åŒ…å«å¾…æ‰“åŒ…èµ„æºçš„æ–‡ä»¶å¤¹è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼Œç”¨äºŽä¿å­˜ç”Ÿæˆçš„æ›´æ–°åŽæ–‡ä»¶
        save_options: ä¿å­˜å’ŒCRCä¿®æ­£çš„é€‰é¡¹
        spine_options: Spineèµ„æºå‡çº§çš„é€‰é¡¹
        enable_rename_fix: æ˜¯å¦å¯ç”¨æ—§ç‰ˆ Spine 3.8 æ–‡ä»¶åä¿®æ­£
        enable_bleed: æ˜¯å¦å¯¹ PNG æ–‡ä»¶è¿›è¡Œ Bleed å¤„ç†
        log: æ—¥å¿—è®°å½•å‡½æ•°ï¼Œé»˜è®¤ä¸ºç©ºå‡½æ•°
    """
    temp_asset_folder = None
    try:
        if enable_rename_fix:
            temp_asset_folder = SpineUtils.normalize_legacy_spine_assets(asset_folder, log)
            asset_folder = temp_asset_folder

        env = load_bundle(target_bundle_path, log)
        if not env:
            return False, t("message.packer.load_target_bundle_failed")
        
        # 1. ä»Žæ–‡ä»¶å¤¹æž„å»º"æ›¿æ¢æ¸…å•"
        replacement_map: dict[AssetKey, AssetContent] = {}
        supported_extensions = {".png", ".skel", ".atlas"}
        input_files = [f for f in asset_folder.iterdir() if f.is_file() and f.suffix.lower() in supported_extensions]

        if not input_files:
            msg = t("message.packer.no_supported_files_found", extensions=', '.join(supported_extensions))
            log(f"âš ï¸ {t('common.warning')}: {msg}")
            return False, msg

        for file_path in input_files:
            asset_key: AssetKey
            content: AssetContent
            suffix: str = file_path.suffix.lower()
            if suffix == ".png":
                asset_key = NameTypeKey(file_path.stem, AssetType.Texture2D.name)
                content = Image.open(file_path).convert("RGBA")
                if enable_bleed:
                    content = ImageUtils.bleed_image(content)
                    log(f"  > {t('log.packer.bleed_processed', name=file_path.stem)}")
            elif suffix in {".skel", ".atlas"}:
                asset_key = NameTypeKey(file_path.name, AssetType.TextAsset.name)
                with open(file_path, "rb") as f:
                    content = f.read()
                
                if file_path.suffix.lower() == '.skel':
                    content = SpineUtils.handle_skel_upgrade(
                        skel_bytes=content,
                        resource_name=asset_key.name,
                        enabled=spine_options.enabled if spine_options else False,
                        converter_path=spine_options.converter_path if spine_options else None,
                        target_version=spine_options.target_version if spine_options else None,
                        log=log
                    )
            else:
                assert(False, f"Unsupported suffix: {suffix}")
                pass
            replacement_map[asset_key] = content
        
        original_tasks_count = len(replacement_map)
        log(t("log.packer.found_files_to_process", count=original_tasks_count))

        # 2. å®šä¹‰ç”¨äºŽåœ¨ bundle ä¸­æŸ¥æ‰¾èµ„æºçš„ key ç”Ÿæˆå‡½æ•°
        strategy_name = 'name_type'
        key_func = MATCH_STRATEGIES[strategy_name]

        # 3. åº”ç”¨æ›¿æ¢
        replacement_count, replaced_assets_log, unmatched_keys = _apply_replacements(env, replacement_map, key_func, log)

        if replacement_count == 0:
            log(f"âš ï¸ {t('common.warning')}: {t('log.packer.no_assets_packed')}")
            log(t("log.packer.check_files_and_bundle"))
            return False, t("message.packer.no_matching_assets_to_pack")
        
        # æŠ¥å‘Šæ›¿æ¢ç»“æžœ
        log(f"\nâœ… {t('log.migration.strategy_success', name=strategy_name, count=replacement_count)}:")
        for item in replaced_assets_log:
            log(f"  - {item}")

        log(f'\n{t("log.packer.packing_complete", success=replacement_count, total=original_tasks_count)}')

        # æŠ¥å‘Šæœªè¢«æ‰“åŒ…çš„æ–‡ä»¶
        if unmatched_keys:
            log(f"âš ï¸ {t('common.warning')}: {t('log.packer.unmatched_files_warning')}:")
            # ä¸ºäº†æ‰¾åˆ°åŽŸå§‹æ–‡ä»¶åï¼Œæˆ‘ä»¬éœ€è¦åå‘æŸ¥æ‰¾
            original_filenames = {
                NameTypeKey(f.stem, AssetType.Texture2D.name): f.name for f in input_files if f.suffix.lower() == '.png'
            }
            original_filenames.update({
                NameTypeKey(f.name, AssetType.TextAsset.name): f.name for f in input_files if f.suffix.lower() in {'.skel', '.atlas'}
            })
            for key in sorted(unmatched_keys):
                if isinstance(key, NameTypeKey):
                    key_display = f"[{key.type}] {key.name}"
                else:
                    key_display = str(key)
                log(f"  - {original_filenames.get(key, key)} ({t('log.packer.attempted_match', key=key_display)})")

        # 4. ä¿å­˜å’Œä¿®æ­£
        output_path = output_dir / target_bundle_path.name
        save_ok, save_message = _save_and_crc(
            env=env,
            output_path=output_path,
            original_bundle_path=target_bundle_path,
            save_options=save_options,
            log=log
        )

        if not save_ok:
            return False, save_message

        log(t("log.file.saved", path=output_path))
        return True, t("message.packer.process_complete", count=replacement_count, button=t("action.replace_original"))

    except Exception as e:
        log(f"\nâŒ {t('common.error')}: {t('log.error_detail', error=e)}")
        log(traceback.format_exc())
        return False, t("message.error_during_process", error=e)
    finally:
        if temp_asset_folder:
            try:
                shutil.rmtree(temp_asset_folder)
            except Exception:
                pass

def process_asset_extraction(
    bundle_path: Path,
    output_dir: Path,
    asset_types_to_extract: set[str],
    downgrade_options: SpineDowngradeOptions | None = None,
    log: LogFunc = no_log,
) -> tuple[bool, str]:
    """
    ä»ŽæŒ‡å®šçš„ Bundle æ–‡ä»¶ä¸­æå–é€‰å®šç±»åž‹çš„èµ„æºåˆ°è¾“å‡ºç›®å½•ã€‚
    æ”¯æŒ Texture2D (ä¿å­˜ä¸º .png) å’Œ TextAsset (æŒ‰åŽŸåä¿å­˜)ã€‚
    å¦‚æžœå¯ç”¨äº†Spineé™çº§é€‰é¡¹ï¼Œå°†è‡ªåŠ¨å¤„ç†Spine 4.xåˆ°3.8çš„é™çº§ã€‚

    Args:
        bundle_path: ç›®æ ‡ Bundle æ–‡ä»¶çš„è·¯å¾„ã€‚
        output_dir: æå–èµ„æºçš„ä¿å­˜ç›®å½•ã€‚
        asset_types_to_extract: éœ€è¦æå–çš„èµ„æºç±»åž‹é›†åˆ (å¦‚ {"Texture2D", "TextAsset"})ã€‚
        downgrade_options: Spineèµ„æºé™çº§çš„é€‰é¡¹ã€‚
        log: æ—¥å¿—è®°å½•å‡½æ•°ã€‚

    Returns:
        ä¸€ä¸ªå…ƒç»„ (æ˜¯å¦æˆåŠŸ, çŠ¶æ€æ¶ˆæ¯)ã€‚
    """
    try:
        log("\n" + "="*50)
        log(t("log.extractor.starting_extraction", filename=bundle_path.name))
        log(t("log.extractor.extraction_types", types=', '.join(asset_types_to_extract)))
        log(f"{t('option.output_dir')}: {output_dir}")

        env = load_bundle(bundle_path, log)
        if not env:
            return False, t("message.load_failed")

        output_dir.mkdir(parents=True, exist_ok=True)
        downgrade_enabled = downgrade_options and downgrade_options.is_valid()

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_extraction_dir = Path(temp_dir)
            log(f"  > {t('log.extractor.using_temp_dir', path=temp_extraction_dir)}")

            # --- é˜¶æ®µ 1: ç»Ÿä¸€æå–æ‰€æœ‰ç›¸å…³èµ„æºåˆ°ä¸´æ—¶ç›®å½• ---
            log(f'\n--- {t("log.section.extract_to_temp")} ---')
            extraction_count = 0
            for obj in env.objects:
                if obj.type.name not in asset_types_to_extract:
                    continue
                # ç¡®ä¿ç±»åž‹åœ¨ç™½åå•ä¸­
                if obj.type not in REPLACEABLE_ASSET_TYPES:
                    continue
                try:
                    data = obj.read()
                    resource_name = getattr(data, 'm_Name', None)
                    if not resource_name:
                        log(f"  > {t('log.extractor.skipping_unnamed', type=obj.type.name)}")
                        continue

                    if obj.type == AssetType.TextAsset:
                        dest_path = temp_extraction_dir / resource_name
                        asset_bytes = data.m_Script.encode("utf-8", "surrogateescape")
                        dest_path.write_bytes(asset_bytes)
                    elif obj.type == AssetType.Texture2D:
                        dest_path = temp_extraction_dir / f"{resource_name}.png"
                        data.image.convert("RGBA").save(dest_path)
                    
                    log(f"  - {dest_path.name}")
                    extraction_count += 1
                except Exception as e:
                    log(f"  âŒ {t('log.extractor.extraction_failed', name=getattr(data, 'm_Name', 'N/A'), error=e)}")

            if extraction_count == 0:
                msg = t("message.extractor.no_assets_found")
                log(f"âš ï¸ {msg}")
                return True, msg

            # --- é˜¶æ®µ 2: å¤„ç†å¹¶ç§»åŠ¨æ–‡ä»¶ ---
            if not downgrade_enabled:
                log(f'\n--- {t("log.section.move_to_output")} ---')
                for item in temp_extraction_dir.iterdir():
                    shutil.copy2(item, output_dir / item.name)
            else:
                log(f'\n--- {t("log.section.process_spine_downgrade")} ---')
                processed_files = set()
                skel_files = list(temp_extraction_dir.glob("*.skel"))

                if not skel_files:
                    log(f'  > {t("log.spine.no_skel_found")}')
                
                for skel_path in skel_files:
                    base_name = skel_path.stem
                    atlas_path = skel_path.with_suffix(".atlas")
                    log(f"\n  > {t('log.extractor.processing_asset_group', name=base_name)}")

                    if not atlas_path.exists():
                        log(f"    - {t('common.warning')}: {t('log.spine.missing_matching_atlas', skel=skel_path.name, atlas=atlas_path.name)}")
                        continue
                    
                    # æ ‡è®°æ­¤èµ„äº§ç»„ä¸­çš„æ‰€æœ‰æ–‡ä»¶ä¸ºå·²å¤„ç†
                    png_paths = list(temp_extraction_dir.glob(f"{base_name}*.png"))
                    processed_files.add(skel_path)
                    processed_files.add(atlas_path)
                    processed_files.update(png_paths)

                    # è°ƒç”¨è¾…åŠ©å‡½æ•°å¤„ç†è¯¥èµ„äº§ç»„
                    SpineUtils.handle_group_downgrade(
                        skel_path, atlas_path, output_dir,
                        downgrade_options.skel_converter_path,
                        downgrade_options.atlas_converter_path,
                        downgrade_options.target_version,
                        log
                    )
                
                # --- é˜¶æ®µ 3: å¤åˆ¶å‰©ä½™çš„ç‹¬ç«‹æ–‡ä»¶ ---
                remaining_files = [item for item in temp_extraction_dir.iterdir() if item not in processed_files]
                
                if remaining_files:
                    log(f'\n--- {t("log.section.copy_standalone_files")} ---')
                    for item in remaining_files:
                        log(f"  - {t('log.extractor.copying_file', name=item.name)}")
                        shutil.copy2(item, output_dir / item.name)

        total_files_extracted = len(list(output_dir.iterdir()))
        success_msg = t("message.extractor.extraction_complete", count=total_files_extracted)
        log(f"\nðŸŽ‰ {success_msg}")
        return True, success_msg

    except Exception as e:
        log(f"\nâŒ {t('common.error')}: {t('log.error_detail', error=e)}")
        log(traceback.format_exc())
        return False, t("message.error_during_process", error=e)

def _extract_assets_from_bundle(
    env: UnityPy.Environment,
    asset_types_to_replace: set[str],
    key_func: KeyGeneratorFunc,
    spine_options: SpineOptions | None,
    log: LogFunc = no_log,
) -> dict[AssetKey, AssetContent]:
    """
    ä»Žæº bundle çš„ env æž„å»ºæ›¿æ¢æ¸…å•
    å³å…¶ä»–å‡½æ•°ä¸­ä½¿ç”¨çš„replacement_map
    """
    replacement_map: dict[AssetKey, AssetContent] = {}
    replace_all = "ALL" in asset_types_to_replace

    for obj in env.objects:
        try:
            data = obj.read()
            
            # ç»Ÿä¸€è¿‡æ»¤ï¼šåªæå–å¯æ›¿æ¢çš„èµ„æºç±»åž‹
            if obj.type not in REPLACEABLE_ASSET_TYPES:
                continue
            
            # å¦‚æžœä¸æ˜¯"ALL"æ¨¡å¼ï¼Œåˆ™åªå¤„ç†åœ¨æŒ‡å®šé›†åˆä¸­çš„ç±»åž‹
            if not replace_all and obj.type.name not in asset_types_to_replace:
                continue

            asset_key = key_func(obj)
            if asset_key is None or not getattr(data, 'm_Name', None):
                continue
            
            content: AssetContent | None = None
            resource_name: str = data.m_Name

            if obj.type == AssetType.Texture2D:
                content: Image.Image = data.image
            elif obj.type == AssetType.TextAsset:
                asset_bytes = data.m_Script.encode("utf-8", "surrogateescape")
                if resource_name.lower().endswith('.skel'):
                    content: bytes = SpineUtils.handle_skel_upgrade(
                        skel_bytes=asset_bytes,
                        resource_name=resource_name,
                        enabled=spine_options.enabled if spine_options else False,
                        converter_path=spine_options.converter_path if spine_options else None,
                        target_version=spine_options.target_version if spine_options else None,
                        log=log
                    )
                else:
                    content: bytes = asset_bytes
            # å¯¹äºŽå…¶ä»–ç±»åž‹ï¼Œå¦‚æžœå¤„äºŽâ€œALLâ€æ¨¡å¼æˆ–è¯¥ç±»åž‹è¢«æ˜Žç¡®è¯·æ±‚ï¼Œåˆ™å¤åˆ¶åŽŸå§‹æ•°æ®
            elif replace_all or obj.type.name in asset_types_to_replace:
                content: bytes = obj.get_raw_data()

            if content is not None:
                replacement_map[asset_key] = content
        except Exception as e:
            log(f"  > âš ï¸ {t('log.extractor.extraction_failed', name=getattr(data, 'm_Name', 'N/A'), error=e)}")

    if replace_all:
        replacement_map["__mode__"] = {"ALL"}

    return replacement_map

def _migrate_bundle_assets(
    old_bundle_path: Path,
    new_bundle_path: Path,
    asset_types_to_replace: set[str],
    spine_options: SpineOptions | None = None,
    log: LogFunc = no_log,
) -> tuple[UnityPy.Environment | None, int]:
    """
    æ‰§è¡Œassetè¿ç§»çš„æ ¸å¿ƒæ›¿æ¢é€»è¾‘ã€‚
    asset_types_to_replace: è¦æ›¿æ¢çš„èµ„æºç±»åž‹é›†åˆï¼ˆå¦‚ {"Texture2D", "TextAsset", "Mesh"} çš„å­é›† æˆ– {"ALL"}ï¼‰
    æŒ‰é¡ºåºå°è¯•å¤šç§åŒ¹é…ç­–ç•¥ï¼ˆpath_id, name_typeï¼‰ï¼Œä¸€æ—¦æœ‰ç­–ç•¥æˆåŠŸæ›¿æ¢äº†è‡³å°‘ä¸€ä¸ªèµ„æºï¼Œå°±åœæ­¢å¹¶è¿”å›žç»“æžœã€‚
    è¿”å›žä¸€ä¸ªå…ƒç»„ (modified_env, replacement_count)ï¼Œå¦‚æžœå¤±è´¥åˆ™ modified_env ä¸º Noneã€‚
    """
    # 1. åŠ è½½ bundles
    log(t("log.migration.extracting_from_old_bundle", types=', '.join(asset_types_to_replace)))
    old_env = load_bundle(old_bundle_path, log)
    if not old_env:
        return None, 0
    
    log(t("log.migration.loading_new_bundle"))
    new_env = load_bundle(new_bundle_path, log)
    if not new_env:
        return None, 0

    # å®šä¹‰åŒ¹é…ç­–ç•¥
    strategies: list[tuple[str, KeyGeneratorFunc]] = [
        ('path_id', MATCH_STRATEGIES['path_id']),
        ('cont_name_type', MATCH_STRATEGIES['cont_name_type']),
        ('name_type', MATCH_STRATEGIES['name_type']),
        # ('container', MATCH_STRATEGIES['container']),
        # å› ä¸ºå¤šä¸ªMeshå¯èƒ½å…±äº«åŒä¸€ä¸ªContainerï¼Œæ‰€ä»¥è¿™ä¸ªç­–ç•¥å¾ˆå¯èƒ½å¤±æ•ˆï¼Œå› æ­¤ä¸ä½¿ç”¨
    ]

    for name, key_func in strategies:
        log(f'\n{t("log.migration.trying_strategy", name=name)}')
        
        # 2. æ ¹æ®å½“å‰ç­–ç•¥ä»Žæ—§ç‰ˆ bundle æž„å»ºâ€œæ›¿æ¢æ¸…å•â€
        log(f'  > {t("log.migration.extracting_from_old_bundle_simple")}')
        old_assets_map = _extract_assets_from_bundle(
            old_env, asset_types_to_replace, key_func, spine_options, log
        )
        
        if not old_assets_map:
            log(f"  > âš ï¸ {t('common.warning')}: {t('log.migration.strategy_no_assets_found', name=name)}")
            continue

        log(f'  > {t("log.migration.extraction_complete", name=name, count=len(old_assets_map))}')

        # 3. æ ¹æ®å½“å‰ç­–ç•¥åº”ç”¨æ›¿æ¢
        log(f'  > {t("log.migration.writing_to_new_bundle")}')
        
        replacement_count, replaced_logs, unmatched_keys = _apply_replacements(
            new_env, old_assets_map, key_func, log)
        
        # 4. å¦‚æžœå½“å‰ç­–ç•¥æˆåŠŸæ›¿æ¢äº†è‡³å°‘ä¸€ä¸ªèµ„æºï¼Œå°±ç»“æŸ
        if replacement_count > 0:
            log(f"\nâœ… {t('log.migration.strategy_success', name=name, count=replacement_count)}:")
            for item in replaced_logs:
                log(f"  - {item}")
            return new_env, replacement_count

        log(f'  > {t("log.migration.strategy_no_match", name=name)}')

    # 5. æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥äº†
    log(f"\nâš ï¸ {t('common.warning')}: {t('log.migration.all_strategies_failed', types=', '.join(asset_types_to_replace))}")
    return None, 0

def process_mod_update(
    old_mod_path: Path,
    new_bundle_path: Path,
    output_dir: Path,
    asset_types_to_replace: set[str],
    save_options: SaveOptions,
    spine_options: SpineOptions | None = None,
    log: LogFunc = no_log,
) -> tuple[bool, str]:
    """
    è‡ªåŠ¨åŒ–Modæ›´æ–°æµç¨‹ã€‚
    
    è¯¥å‡½æ•°æ˜¯Modæ›´æ–°å·¥å…·çš„æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼Œè´Ÿè´£å°†æ—§ç‰ˆModä¸­çš„èµ„æºæ›¿æ¢åˆ°æ–°ç‰ˆæ¸¸æˆèµ„æºä¸­ï¼Œ
    å¹¶å¯é€‰åœ°è¿›è¡ŒCRCæ ¡éªŒä¿®æ­£ä»¥ç¡®ä¿æ–‡ä»¶å…¼å®¹æ€§ã€‚
    
    å¤„ç†æµç¨‹çš„ä¸»è¦é˜¶æ®µï¼š
    - assetè¿ç§»ï¼šå°†æ—§ç‰ˆModä¸­çš„æŒ‡å®šç±»åž‹èµ„æºæ›¿æ¢åˆ°æ–°ç‰ˆèµ„æºæ–‡ä»¶ä¸­
        - æ”¯æŒæ›¿æ¢Texture2Dã€TextAssetã€Meshç­‰èµ„æºç±»åž‹
        - å¯é€‰åœ°å‡çº§SpineåŠ¨ç”»èµ„æºçš„Skelç‰ˆæœ¬
    - CRCä¿®æ­£ï¼šæ ¹æ®é€‰é¡¹å†³å®šæ˜¯å¦å¯¹æ–°ç”Ÿæˆçš„æ–‡ä»¶è¿›è¡ŒCRCæ ¡éªŒä¿®æ­£
    
    Args:
        old_mod_path: æ—§ç‰ˆModæ–‡ä»¶çš„è·¯å¾„
        new_bundle_path: æ–°ç‰ˆæ¸¸æˆèµ„æºæ–‡ä»¶çš„è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼Œç”¨äºŽä¿å­˜ç”Ÿæˆçš„æ›´æ–°åŽæ–‡ä»¶
        asset_types_to_replace: éœ€è¦æ›¿æ¢çš„èµ„æºç±»åž‹é›†åˆï¼ˆå¦‚ {"Texture2D", "TextAsset"}ï¼‰
        save_options: ä¿å­˜å’ŒCRCä¿®æ­£çš„é€‰é¡¹
        spine_options: Spineèµ„æºå‡çº§çš„é€‰é¡¹
        log: æ—¥å¿—è®°å½•å‡½æ•°ï¼Œé»˜è®¤ä¸ºç©ºå‡½æ•°
    
    Returns:
        tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, çŠ¶æ€æ¶ˆæ¯) çš„å…ƒç»„
    """
    try:
        log("="*50)
        log(f'  > {t("log.mod_update.using_old_mod", name=old_mod_path.name)}')
        log(f'  > {t("log.mod_update.using_new_resource", name=new_bundle_path.name)}')

        # è¿›è¡Œassetè¿ç§»
        log(f'\n--- {t("log.section.asset_migration")} ---')
        modified_env, replacement_count = _migrate_bundle_assets(
            old_bundle_path=old_mod_path, 
            new_bundle_path=new_bundle_path, 
            asset_types_to_replace=asset_types_to_replace, 
            spine_options=spine_options,
            log = log
        )

        if not modified_env:
            return False, t("message.mod_update.migration_failed")
        if replacement_count == 0:
            return False, t("message.mod_update.no_matching_assets_to_replace")
        
        log(f'  > {t("log.mod_update.migration_complete", count=replacement_count)}')
        
        # ä¿å­˜å’Œä¿®æ­£æ–‡ä»¶
        output_path = output_dir / new_bundle_path.name
        save_ok, save_message = _save_and_crc(
            env=modified_env,
            output_path=output_path,
            original_bundle_path=new_bundle_path,
            save_options=save_options,
            log=log
        )

        if not save_ok:
            return False, save_message

        log(t("log.file.saved", path=output_path))
        log(f"\nðŸŽ‰ {t('log.mod_update.all_processes_complete')}")
        return True, t("message.mod_update.success")

    except Exception as e:
        log(f"\nâŒ {t('common.error')}: {t('log.error_processing', error=e)}")
        log(traceback.format_exc())
        return False, t("message.error_during_process", error=e)

def process_batch_mod_update(
    mod_file_list: list[Path],
    search_paths: list[Path],
    output_dir: Path,
    asset_types_to_replace: set[str],
    save_options: SaveOptions,
    spine_options: SpineOptions | None,
    log: LogFunc = no_log,
    progress_callback: Callable[[int, int, str], None] | None = None,
) -> tuple[int, int, list[str]]:
    """
    æ‰§è¡Œæ‰¹é‡Modæ›´æ–°çš„æ ¸å¿ƒé€»è¾‘ã€‚

    Args:
        mod_file_list: å¾…æ›´æ–°çš„æ—§Modæ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
        search_paths: ç”¨äºŽæŸ¥æ‰¾æ–°ç‰ˆbundleæ–‡ä»¶çš„ç›®å½•åˆ—è¡¨ã€‚
        output_dir: è¾“å‡ºç›®å½•ã€‚
        asset_types_to_replace: éœ€è¦æ›¿æ¢çš„èµ„æºç±»åž‹é›†åˆã€‚
        save_options: ä¿å­˜å’ŒCRCä¿®æ­£çš„é€‰é¡¹ã€‚
        spine_options: Spineèµ„æºå‡çº§çš„é€‰é¡¹ã€‚
        log: æ—¥å¿—è®°å½•å‡½æ•°ã€‚
        progress_callback: è¿›åº¦å›žè°ƒå‡½æ•°ï¼Œç”¨äºŽæ›´æ–°UIã€‚
                           æŽ¥æ”¶ (å½“å‰ç´¢å¼•, æ€»æ•°, æ–‡ä»¶å)ã€‚

    Returns:
        tuple[int, int, list[str]]: (æˆåŠŸè®¡æ•°, å¤±è´¥è®¡æ•°, å¤±è´¥ä»»åŠ¡è¯¦æƒ…åˆ—è¡¨)
    """
    total_files = len(mod_file_list)
    success_count = 0
    fail_count = 0
    failed_tasks = []

    # éåŽ†æ¯ä¸ªæ—§Modæ–‡ä»¶
    for i, old_mod_path in enumerate(mod_file_list):
        current_progress = i + 1
        filename = old_mod_path.name
        
        if progress_callback:
            progress_callback(current_progress, total_files, filename)

        log("\n" + "=" * 50)
        log(t("log.status.processing_batch", current=current_progress, total=total_files, filename=filename))

        # æŸ¥æ‰¾å¯¹åº”çš„æ–°èµ„æºæ–‡ä»¶
        new_bundle_path, find_message = find_new_bundle_path(
            old_mod_path, search_paths, log
        )

        if not new_bundle_path:
            log(f'âŒ {t("log.search.find_failed", message=find_message)}')
            fail_count += 1
            failed_tasks.append(f"{filename} - {t('log.search.find_failed', message=find_message)}")
            continue

        # æ‰§è¡ŒModæ›´æ–°å¤„ç†
        success, process_message = process_mod_update(
            old_mod_path=old_mod_path,
            new_bundle_path=new_bundle_path,
            output_dir=output_dir,
            asset_types_to_replace=asset_types_to_replace,
            save_options=save_options,
            spine_options=spine_options,
            log=log
        )

        if success:
            log(f'âœ… {t("log.mod_update.process_success", filename=filename)}')
            success_count += 1
        else:
            log(f'âŒ {t("log.mod_update.process_failed", filename=filename, message=process_message)}')
            fail_count += 1
            failed_tasks.append(f"{filename} - {process_message}")

    return success_count, fail_count, failed_tasks

# ====== æ—¥æœå¤„ç†ç›¸å…³ ======

# å°†æ—¥æœæ–‡ä»¶åä¸­çš„ç±»åž‹æ ‡è¯†ç¬¦æ˜ å°„åˆ°UnityPyçš„AssetTypeåç§°
JP_FILENAME_TYPE_MAP = {
    "textures": "Texture2D",
    "textassets": "TextAsset",
    "materials": "Material",
    "meshes": "Mesh",
    "animationclip": "AnimationClip",
    "audio": "AudioClip",
    "prefabs": "Prefab",
}

# å¯æ›¿æ¢çš„èµ„æºç±»åž‹ç™½åå•
# è¿™äº›æ˜¯å®žé™…çš„èµ„æºç±»åž‹ï¼Œä¸åº”åŒ…æ‹¬å®¹å™¨å¯¹è±¡ï¼ˆå¦‚ AssetBundleï¼‰æˆ–å…ƒæ•°æ®å¯¹è±¡
REPLACEABLE_ASSET_TYPES: set[AssetType] = {
    # çº¹ç†ç±»
    AssetType.Texture2D,
    AssetType.Texture3D,
    AssetType.Cubemap,
    AssetType.RenderTexture,
    AssetType.CustomRenderTexture,
    AssetType.Sprite,
    AssetType.SpriteAtlas,

    # æ–‡æœ¬å’Œè„šæœ¬ç±»
    AssetType.TextAsset,
    AssetType.MonoBehaviour,
    AssetType.MonoScript,

    # éŸ³é¢‘ç±»
    AssetType.AudioClip,

    # ç½‘æ ¼å’Œæè´¨ç±»
    AssetType.Mesh,
    AssetType.Material,
    AssetType.Shader,

    # åŠ¨ç”»ç±»
    AssetType.AnimationClip,
    AssetType.Animator,
    AssetType.AnimatorController,
    AssetType.RuntimeAnimatorController,
    AssetType.Avatar,
    AssetType.AvatarMask,

    # å­—ä½“ç±»
    AssetType.Font,

    # è§†é¢‘ç±»
    AssetType.VideoClip,

    # åœ°å½¢ç±»
    AssetType.TerrainData,

    # å…¶ä»–èµ„æºç±»
    AssetType.PhysicMaterial,
    AssetType.ComputeShader,
    AssetType.Flare,
    AssetType.LensFlare,
}

def _get_asset_types_from_jp_filenames(jp_paths: list[Path]) -> set[str]:
    """
    åˆ†æžæ—¥æœbundleæ–‡ä»¶ååˆ—è¡¨ï¼Œä»¥ç¡®å®šå®ƒä»¬åŒ…å«çš„èµ„æºç±»åž‹ã€‚
    åªè¿”å›žå¯æ›¿æ¢çš„èµ„æºç±»åž‹ã€‚
    """
    asset_types = set()
    # ç”¨äºŽæŸ¥æ‰¾ç±»åž‹éƒ¨åˆ†çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ "-textures-"
    type_pattern = re.compile(r'-(' + '|'.join(JP_FILENAME_TYPE_MAP.keys()) + r')-')

    for path in jp_paths:
        match = type_pattern.search(path.name)
        if match:
            type_key = match.group(1)
            asset_type_name = JP_FILENAME_TYPE_MAP.get(type_key)
            if asset_type_name:
                # åªæ·»åŠ åœ¨ç™½åå•ä¸­çš„ç±»åž‹
                try:
                    asset_type = AssetType[asset_type_name]
                    if asset_type in REPLACEABLE_ASSET_TYPES:
                        asset_types.add(asset_type_name)
                except KeyError:
                    pass

    return asset_types

def find_all_jp_counterparts(
    global_bundle_path: Path,
    search_dirs: list[Path],
    log: LogFunc = no_log,
) -> list[Path]:
    """
    æ ¹æ®å›½é™…æœbundleæ–‡ä»¶ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç›¸å…³çš„æ—¥æœ bundle æ–‡ä»¶ã€‚
    æ—¥æœæ–‡ä»¶é€šå¸¸åŒ…å«é¢å¤–çš„ç±»åž‹æ ‡è¯†ï¼ˆå¦‚ -materials-, -timelines- ç­‰ï¼‰ã€‚

    Args:
        global_bundle_path: å›½é™…æœbundleæ–‡ä»¶çš„è·¯å¾„ã€‚
        search_dirs: ç”¨äºŽæŸ¥æ‰¾çš„ç›®å½•åˆ—è¡¨ã€‚
        log: æ—¥å¿—è®°å½•å‡½æ•°ã€‚

    Returns:
        æ‰¾åˆ°çš„æ—¥æœæ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
    """
    log(t("log.jp_convert.searching_jp_counterparts", name=global_bundle_path.name))

    # 1. ä»Žå›½é™…æœæ–‡ä»¶åæå–å‰ç¼€
    prefix, prefix_message = get_filename_prefix(global_bundle_path.name, log)
    if not prefix:
        log(f'  > âŒ {t("log.search.find_failed")}: {prefix_message}')
        return []
    
    log(f"  > {t('log.search.file_prefix', prefix=prefix)}")

    jp_files: list[Path] = []
    seen_names = set()

    # 2. åœ¨æœç´¢ç›®å½•ä¸­æŸ¥æ‰¾åŒ¹é…å‰ç¼€çš„æ‰€æœ‰æ–‡ä»¶
    for search_dir in search_dirs:
        if not (search_dir.exists() and search_dir.is_dir()):
            continue
        
        for file_path in search_dir.iterdir():
            # æŽ’é™¤è‡ªèº«
            if file_path.name == global_bundle_path.name:
                continue
                
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä»¥é€šç”¨å‰ç¼€å¼€å¤´ï¼Œä¸”æ˜¯ bundle æ–‡ä»¶
            if file_path.is_file() and file_path.name.startswith(prefix) and file_path.suffix == '.bundle':
                if file_path.name not in seen_names:
                    jp_files.append(file_path)
                    seen_names.add(file_path.name)
                    log(f"  > {t('log.jp_convert.found_match', path=file_path.name)}")

    return jp_files

def process_jp_to_global_conversion(
    global_bundle_path: Path,
    jp_bundle_paths: list[Path],
    output_dir: Path,
    save_options: SaveOptions,
    log: LogFunc = no_log,
) -> tuple[bool, str]:
    """
    å¤„ç†æ—¥æœè½¬å›½é™…æœçš„è½¬æ¢ã€‚
    
    å°†æ—¥æœå¤šä¸ªèµ„æºbundleä¸­çš„èµ„æºï¼Œæ›¿æ¢åˆ°å›½é™…æœçš„åŸºç¡€bundleæ–‡ä»¶ä¸­å¯¹åº”çš„éƒ¨åˆ†ã€‚
    æ­¤è¿‡ç¨‹åªæ›¿æ¢åŒååŒç±»åž‹çš„çŽ°æœ‰èµ„æºï¼Œä¸æ·»åŠ æ–°èµ„æºã€‚
    
    Args:
        global_bundle_path: å›½é™…æœbundleæ–‡ä»¶è·¯å¾„ï¼ˆä½œä¸ºåŸºç¡€ï¼‰
        jp_bundle_paths: æ—¥æœbundleæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        save_options: ä¿å­˜å’ŒCRCä¿®æ­£çš„é€‰é¡¹
        log: æ—¥å¿—è®°å½•å‡½æ•°
    
    Returns:
        tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, çŠ¶æ€æ¶ˆæ¯) çš„å…ƒç»„
    """
    try:
        log("="*50)
        log(t("log.jp_convert.starting_jp_to_global"))
        log(f'  > {t("log.jp_convert.global_base_file", name=global_bundle_path.name)}')
        log(f'  > {t("log.jp_convert.jp_files_count", count=len(jp_bundle_paths))}')
        
        # 1. ä»Žæ‰€æœ‰æ—¥æœåŒ…ä¸­æž„å»ºä¸€ä¸ªå®Œæ•´çš„"æ›¿æ¢æ¸…å•"
        log(f'\n--- {t("log.section.extracting_from_jp")} ---')
        replacement_map: dict[AssetKey, AssetContent] = {}
        strategy_name = 'cont_name_type'
        key_func = MATCH_STRATEGIES[strategy_name]
        
        # æ ¹æ®æ—¥æœæ–‡ä»¶ååŠ¨æ€ç¡®å®šè¦æå–çš„èµ„æºç±»åž‹
        asset_types = _get_asset_types_from_jp_filenames(jp_bundle_paths)

        total_files = len(jp_bundle_paths)
        for i, jp_path in enumerate(jp_bundle_paths, 1):
            log(t("log.processing_filename_with_progress", current=i, total=total_files, name=jp_path.name))
            jp_env = load_bundle(jp_path, log)
            if not jp_env:
                log(f"    > âš ï¸ {t('message.load_failed')}: {jp_path.name}")
                continue
            
            # æå–èµ„æºå¹¶åˆå¹¶åˆ°ä¸»æ¸…å•
            jp_assets = _extract_assets_from_bundle(
                jp_env, asset_types, key_func, None, log
            )
            replacement_map.update(jp_assets)

        if not replacement_map:
            msg = t("message.jp_convert.no_assets_in_source")
            log(f"  > âš ï¸ {msg}")
            return False, msg
        
        log(f"  > {t('log.jp_convert.extracted_count_from_jp', count=len(replacement_map))}")

        # 2. åŠ è½½å›½é™…æœ base å¹¶åº”ç”¨æ›¿æ¢
        log(f'\n--- {t("log.section.applying_to_global")} ---')
        global_env = load_bundle(global_bundle_path, log)
        if not global_env:
            return False, t("message.jp_convert.load_global_failed")
        
        replacement_count, replaced_logs, _ = _apply_replacements(
            global_env, replacement_map, key_func, log
        )
        
        if replacement_count == 0:
            log(f"  > âš ï¸ {t('log.jp_convert.no_assets_replaced')}")
            return False, t("message.jp_convert.no_assets_matched")
            
        log(f"\nâœ… {t('log.migration.strategy_success', name=strategy_name, count=replacement_count)}:")
        for item in replaced_logs:
            log(f"  - {item}")
        
        # 3. ä¿å­˜æœ€ç»ˆæ–‡ä»¶
        output_path = output_dir / global_bundle_path.name
        save_ok, save_message = _save_and_crc(
            env=global_env,
            output_path=output_path,
            original_bundle_path=global_bundle_path,
            save_options=save_options,
            log=log
        )
        
        if not save_ok:
            return False, save_message
        
        log(f"  âœ… {t('log.file.saved', path=output_path)}")
        log(f"\nðŸŽ‰ {t('log.jp_convert.jp_to_global_complete')}")
        return True, t("message.jp_convert.jp_to_global_success", asset_count=replacement_count)
        
    except Exception as e:
        log(f"\nâŒ {t('common.error')}: {t('log.jp_convert.error_jp_to_global', error=e)}")
        log(traceback.format_exc())
        return False, t("message.jp_convert.conversion_error", error=e)
        
def process_global_to_jp_conversion(
    global_bundle_path: Path,
    jp_template_paths: list[Path],
    output_dir: Path,
    save_options: SaveOptions,
    log: LogFunc = no_log,
) -> tuple[bool, str]:
    """
    å¤„ç†å›½é™…æœè½¬æ—¥æœçš„è½¬æ¢ã€‚
    
    å°†ä¸€ä¸ªå›½é™…æœæ ¼å¼çš„bundleæ–‡ä»¶ï¼Œä½¿ç”¨å¤šä¸ªæ—¥æœbundleä½œä¸ºæ¨¡æ¿ï¼Œ
    å°†å›½é™…æœçš„èµ„æºåˆ†å‘æ›¿æ¢åˆ°å¯¹åº”çš„æ—¥æœæ–‡ä»¶ä¸­ã€‚
    åªæ›¿æ¢æ¨¡æ¿ä¸­å·²å­˜åœ¨çš„åŒååŒç±»åž‹èµ„æºã€‚
    
    Args:
        global_bundle_path: å¾…è½¬æ¢çš„å›½é™…æœbundleæ–‡ä»¶è·¯å¾„ã€‚
        jp_template_paths: æ—¥æœbundleæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆç”¨ä½œæ¨¡æ¿ï¼‰ã€‚
        output_dir: è¾“å‡ºç›®å½•ã€‚
        save_options: ä¿å­˜é€‰é¡¹ã€‚
        log: æ—¥å¿—è®°å½•å‡½æ•°ã€‚
    
    Returns:
        tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, çŠ¶æ€æ¶ˆæ¯) çš„å…ƒç»„
    """
    try:
        log("="*50)
        log(t("log.jp_convert.starting_global_to_jp"))
        log(f'  > {t("log.jp_convert.global_source_file", name=global_bundle_path.name)}')
        log(f'  > {t("log.jp_convert.jp_files_count", count=len(jp_template_paths))}')
        
        # 1. åŠ è½½å›½é™…æœæºæ–‡ä»¶å¹¶æž„å»ºæºèµ„æºæ¸…å•
        global_env = load_bundle(global_bundle_path, log)
        if not global_env:
            return False, t("message.jp_convert.load_global_source_failed")
        
        log(f'\n--- {t("log.section.extracting_from_global")} ---')
        strategy_name = 'cont_name_type'
        key_func = MATCH_STRATEGIES[strategy_name]

        # æ ¹æ®æ—¥æœæ¨¡æ¿æ–‡ä»¶åç¡®å®šè¦æå–å“ªäº›ç±»åž‹çš„èµ„æº
        asset_types = _get_asset_types_from_jp_filenames(jp_template_paths)
        
        source_replacement_map = _extract_assets_from_bundle(
            global_env, asset_types, key_func, None, log
        )
        
        if not source_replacement_map:
            msg = t("message.jp_convert.no_assets_in_source")
            log(f"  > âš ï¸ {msg}")
            return False, msg
        log(f"  > {t('log.jp_convert.extracted_count', count=len(source_replacement_map))}")

        success_count = 0
        total_changes = 0
        total_files = len(jp_template_paths)
        
        # 2. éåŽ†æ¯ä¸ªæ—¥æœæ¨¡æ¿æ–‡ä»¶è¿›è¡Œå¤„ç†
        for i, jp_template_path in enumerate(jp_template_paths, 1):
            log(t("log.processing_filename_with_progress", current=i, total=total_files, name=jp_template_path.name))
            
            template_env = load_bundle(jp_template_path, log)
            if not template_env:
                log(f"  > âŒ {t('message.load_failed')}: {jp_template_path.name}")
                continue

            # åº”ç”¨æ›¿æ¢ï¼Œå‡½æ•°ä¼šè‡ªåŠ¨åŒ¹é…å¹¶æ›¿æ¢å­˜åœ¨äºŽæ¨¡æ¿ä¸­çš„èµ„æº
            replacement_count, replaced_logs, _ = _apply_replacements(
                template_env, source_replacement_map, key_func, log
            )
            
            if replacement_count > 0:
                log(f"\nâœ… {t('log.migration.strategy_success', name=strategy_name, count=replacement_count)}:")
                for item in replaced_logs:
                    log(f"  - {item}")
                
                output_path = output_dir / jp_template_path.name
                save_ok, save_msg = _save_and_crc(
                    env=template_env,
                    output_path=output_path,
                    original_bundle_path=jp_template_path,
                    save_options=save_options,
                    log=log
                )
                if save_ok:
                    log(f"  âœ… {t('log.file.saved', path=output_path)}")
                    success_count += 1
                    total_changes += replacement_count
                else:
                    log(f"  âŒ {t('log.file.save_failed', path=output_path, error=save_msg)}")
            else:
                log(f"  > {t('log.file.no_changes_made')}")

        log(f'\n--- {t("log.section.conversion_complete")} ---')
        log(f"{t('log.jp_convert.global_to_jp_complete')}")
        return True, t("message.jp_convert.global_to_jp_success",bundle_count=success_count, asset_count=total_changes)
        
    except Exception as e:
        log(f"\nâŒ {t('common.error')}: {t('log.jp_convert.error_global_to_jp', error=e)}")
        log(traceback.format_exc())
        return False, t("message.jp_convert.conversion_error", error=e)